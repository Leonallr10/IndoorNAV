<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Indoor Navigation</title>
<!-- Include OpenCV.js -->
<script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
<style>
    body { text-align: center; font-family: Arial, sans-serif; }
    video { border: 2px solid #333; margin-bottom: 10px; }
    canvas { border: 2px solid #333; }
    .arrow { position: absolute; top: 20px; left: 50%; transform: translateX(-50%); font-size: 24px; }
</style>
</head>

<body>

<h2>Indoor Navigation System</h2>
<video id="video" width="640" height="480" autoplay></video>
<canvas id="canvas" width="640" height="480"></canvas>
<div id="arrow" class="arrow"></div>

<script>
    // Key points in Matterport (manually recorded)
    const keyPoints = [
        { id: 'entrance', label: 'Entrance', position: { x: 2.5, y: 0, z: 3.0 } },
        { id: 'lobby', label: 'Lobby', position: { x: 5.0, y: 0, z: 4.5 } },
        { id: 'conference', label: 'Conference Room', position: { x: 8.0, y: 0, z: 6.0 } }
    ];

    // Request camera access
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const context = canvas.getContext("2d");
    const arrowDiv = document.getElementById("arrow");

    navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
        .then(stream => video.srcObject = stream)
        .catch(console.error);

    // Called when OpenCV.js is ready
    function onOpenCvReady() {
        console.log("OpenCV.js is ready!");
        const cap = new cv.VideoCapture(video);
        const frame = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        const gray = new cv.Mat();

        const orb = new cv.ORB();
        const bf = new cv.BFMatcher();

        // Generate descriptors for key points (mockup example)
        const keyPointDescriptors = keyPoints.map(point => ({
            id: point.id,
            label: point.label,
            descriptor: new cv.Mat(1, 32, cv.CV_8U) // Mockup descriptor
        }));

        function processFrame() {
            cap.read(frame);
            cv.cvtColor(frame, gray, cv.COLOR_RGBA2GRAY);

            let keypoints = new cv.KeyPointVector();
            let descriptors = new cv.Mat();
            orb.detectAndCompute(gray, new cv.Mat(), keypoints, descriptors);

            // Compare with stored key points
            let nearest = null;
            let minDist = Infinity;

            keyPointDescriptors.forEach(point => {
                let matches = new cv.DMatchVector();
                bf.match(descriptors, point.descriptor, matches);
                let dist = matches.get(0).distance;
                if (dist < minDist) {
                    minDist = dist;
                    nearest = point;
                }
            });

            // Show arrow direction
            if (nearest) {
                arrowDiv.innerText = `â†’ Go to: ${nearest.label}`;
            } else {
                arrowDiv.innerText = "";
            }

            cv.imshow("canvas", frame);
            requestAnimationFrame(processFrame);
        }

        requestAnimationFrame(processFrame);
    }
</script>

</body>
</html>
