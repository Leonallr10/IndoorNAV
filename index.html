<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Indoor Navigation</title>
<!-- Include OpenCV.js -->
<script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
<style>
    body { text-align: center; font-family: Arial, sans-serif; background-color: #f0f0f0; margin: 0; padding: 20px; }
    video, canvas { border: 2px solid #333; margin-bottom: 10px; border-radius: 8px; }
    .arrow { font-size: 24px; margin-top: 10px; }
    .status { font-size: 18px; margin-top: 5px; color: #555; }
</style>
</head>

<body>

<h2>Indoor Navigation System</h2>
<video id="video" width="640" height="480" autoplay></video>
<canvas id="canvas" width="640" height="480"></canvas>
<div id="arrow" class="arrow">Detecting...</div>
<div id="status" class="status">Waiting for camera...</div>

<script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const context = canvas.getContext("2d");
    const arrowDiv = document.getElementById("arrow");
    const statusDiv = document.getElementById("status");

    // Request back camera access
    navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
        .then(stream => {
            video.srcObject = stream;
            statusDiv.innerText = "Camera access granted";
        })
        .catch(error => {
            console.error("Camera access denied", error);
            statusDiv.innerText = "Camera access denied";
        });

    // Key points in Matterport (manually recorded with approx. coordinates)
    const keyPoints = [
        { id: 'entrance', label: 'Entrance', x: 100, y: 150 },
        { id: 'lobby', label: 'Lobby', x: 300, y: 250 },
        { id: 'conference', label: 'Conference Room', x: 500, y: 350 }
    ];

    // Feature extraction and matching
    function onOpenCvReady() {
        statusDiv.innerText = "OpenCV.js is ready!";
        const cap = new cv.VideoCapture(video);
        const frame = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        const gray = new cv.Mat();
        const orb = new cv.ORB();
        const bf = new cv.BFMatcher();

        // Create fake descriptors for key points (for demonstration)
        const keyPointDescriptors = keyPoints.map(point => ({
            id: point.id,
            label: point.label,
            descriptor: new cv.Mat(1, 32, cv.CV_8U)
        }));

        function processFrame() {
            cap.read(frame);
            cv.cvtColor(frame, gray, cv.COLOR_RGBA2GRAY);

            let keypoints = new cv.KeyPointVector();
            let descriptors = new cv.Mat();
            orb.detectAndCompute(gray, new cv.Mat(), keypoints, descriptors);

            // Compare with key points using a mockup method
            let nearest = null;
            let minDist = Infinity;

            keyPointDescriptors.forEach(point => {
                if (descriptors.rows > 0) {
                    let matches = new cv.DMatchVector();
                    bf.match(descriptors, point.descriptor, matches);
                    if (matches.size() > 0) {
                        let dist = matches.get(0).distance;
                        if (dist < minDist) {
                            minDist = dist;
                            nearest = point;
                        }
                    }
                }
            });

            // Show direction
            if (nearest) {
                arrowDiv.innerText = `â†’ Go to: ${nearest.label}`;
            } else {
                arrowDiv.innerText = "No matching point detected";
            }

            cv.imshow("canvas", frame);
            requestAnimationFrame(processFrame);
        }

        requestAnimationFrame(processFrame);
    }
</script>

</body>
</html>
